---
title: "Time Series NYC Bike Demand Forecast Project"
author: "Yezi Liu"
date: "2024-04-24"
output: html_document
---

## Project Summary
#### Introduction
This notebook is to analyze the daily time series data of Citi Bike rides in NYC after Covid from 2022 March 1st to 2024 March 31st. The goal is to forecast NYC bike demand to help Citi Bike company better optimize bike distribution and maintenance planning in NYC.

#### Datasets
1. Citi Bike Trip Data: https://citibikenyc.com/system-data
2. NYC Weather Data: https://mesonet.agron.iastate.edu/request/download.phtml?network=NY_ASOS

The final data includes the bike demand variable "number_of_rides" and numerical weather variables. I included weather variables to help predict the bike demand in some of the models below.

Note: I aggregated 3.3 million bike rides record in 2 years into daily time series and combined it with averaged daily weather data. These data pre-processing steps are omitted for simplicity. 

#### Project Sections
1. Daily Time Series EDA

Investigated the characteristics of the time series, such as variance, trend, seasonality, stationarity, etc.

2. Model Selection & Model Estimation & Model Diagnostics

Experimented with 6 types of models, optimized model parameters, and conducted model diagnostics based on several criteria, such as AICc and residuals.

Model 1: SARIMA(single seasonality)

Model 2: Linear Regression(Weather Predictors)

Model 3: Regression with ARIMA Errors(Weather Predictors)

Model 4: Dynamic Harmonic Regression(Multi-seasonality)

Model 5: TBATS(Complex Seasonality)

Model 6: Intervention Analysis(No Intervention Effect from Covid-19)


3. Model Evaluation of Forecast Accuracy via Cross-Validation

Selected Dynamic Harmonic Regression Model as the best model due to the multi-seasonality nature of the data and evaluated the model's forecast accuracy via cross-validation using various error metrics.

4. Future Forecast by Dynamic Harmonic Regression

Used the best Dynamic Harmonic Regression to forecast next 30 days(April 2024) and compared forecast values against actual Citi Bike rides.

5. Future Work

#### Author & Platform
Yezi Liu conducted this project independently using R Studio.

```{r, echo = FALSE}
knitr::opts_chunk$set(
  fig.path = "README_figs/README-"
)
```

```{r setup, include=FALSE}
options(repos = c(CRAN = "https://cran.r-project.org"))
knitr::opts_chunk$set(echo = TRUE)
install.packages("dplyr")
install.packages("lubridate")
install.packages('forecast')
install.packages('tseries')
install.packages("lubridate")
install.packages("urca")
install.packages("uroot", repos="http://R-Forge.R-project.org")
install.packages("RColorBrewer")
install.packages('fpp')
install.packages('TSA')
install.packages('Metrics')
```


## 1. Daily Time Series EDA 

```{r}
final_average_df <- read.csv("final_daily_nyc_df.csv")
daily_ts <- ts(final_average_df$number_of_rides, start = c(2022, 60), frequency = 365.25)
```


The meaning of frequency:

Frequency = 365.25: Forecasting functions will consider the data as having a daily cycle throughout the year, accounting for leap years over long-term predictions. This can affect the forecasting of trends and seasonality.

Frequency = 1: The data are considered as sequential with no seasonal or cyclic pattern, so forecasts will not try to model any periodic changes.


```{r}
print(head(daily_ts))
print(length(daily_ts))
plot(daily_ts, xlab = "Time", ylab = "Number of Rides", main = "Daily Bike Rides from March 2022 to March 2024")
```

### Box Cox Transformation

```{r}
library(forecast)
lambda <- BoxCox.lambda(daily_ts)
daily_ts_boxcox <- BoxCox(daily_ts, lambda)

plot(daily_ts_boxcox, main = paste("Box-Cox Transformed Time Series Data, Lambda =", round(lambda, 2)), xlab = "Time", ylab = "Transformed Bike Rides")
```

lambda = 0.37: a Box-Cox transformation is needed to stabilize the variance.


### ACF & PACF

```{r}
library(forecast)

Acf(daily_ts, main="ACF for Daily Demand of Bike Rides")
Pacf(daily_ts, main="PACF for Daily Demand of Bike Rides")
```

Observations: 

1. Non-stationary 
2. Annual seasonality in the long term
3. Potential weekly seasonality in the short term(will analyze later)


### Decompose Method 1

```{r}
bike_decompose <- decompose(daily_ts)
plot(bike_decompose)
```


### Decompose Method 2

```{r}
library(forecast) 
bike_decompose <- stl(daily_ts, s.window="periodic")
plot(bike_decompose)
```


```{r}
plot(bike_decompose$time.series[, "trend"], main="Trend Component")
plot(bike_decompose$time.series[, "seasonal"], main="Seasonal Component")
plot(bike_decompose$time.series[, "remainder"], main="Residual Component")
```

### KPSS Test to check stationarity(trend)

```{r}
library(tseries)
kpss_test_original <- kpss.test(daily_ts)
print("KPSS Test for Original Data:")
print(kpss_test_original)
```

p-value = 0.02 < 0.05: I reject hypothesis that the time series is trend-stationary, indicating non-stationary for increasing trend(Need trend differencing d = 1).


### ADF Test to check stationarity

```{r}
library(tseries)
adf_test <- adf.test(daily_ts, alternative = "stationary")
adf_test$p.value
```

A larger p-value (0.07 > 0.05) indicates I fail to reject the null hypothesis, and conclude that the series is nonstationary.


### Seasonal Differencing

#### Weekly Seasonality Testing
```{r}
library(tseries)
daily_ts_seasonal_diff1 <- diff(daily_ts, lag=7)
kpss_test <- kpss.test(daily_ts_seasonal_diff1)
print("KPSS Test for Weekly Seasonality:")
print(kpss_test)

adf_test <- adf.test(daily_ts_seasonal_diff1, alternative = "stationary")
print("ADF Test P-value for Weekly Seasonality:")
adf_test$p.value
```

The time series is stationary after weekly seasonal differencing.


#### Monthly Seasonality Testing
```{r}
library(tseries)
daily_ts_seasonal_diff2 <- diff(daily_ts, lag=28)
kpss_test <- kpss.test(daily_ts_seasonal_diff2)
print("KPSS Test for Monthly Seasonality:")
print(kpss_test)

adf_test <- adf.test(daily_ts_seasonal_diff2, alternative = "stationary")
print("ADF Test P-value for Monthly Seasonality:")
adf_test$p.value
```

The time series is stationary after monthly seasonal differencing.


#### Annual Seasonality Testing
```{r}
library(tseries)
daily_ts_seasonal_diff3 <- diff(daily_ts, lag=365)
kpss_test <- kpss.test(daily_ts_seasonal_diff3)
print("KPSS Test for Annual Seasonality:")
print(kpss_test)

adf_test <- adf.test(daily_ts_seasonal_diff3, alternative = "stationary")
print("ADF Test P-value for Annual Seasonality:")
adf_test$p.value
```

The time series is stationary after annual seasonal differencing.

Conclusion: 
The daily time series might have multiple seasonalities(weekly, monthly, and annual seasonality).


## 2. Model Selection & Model Estimation & Model Diagnostics

### Model 1: SARIMA

```{r}
arima_model_1 <- auto.arima(daily_ts, seasonal = TRUE, lambda = 0.37)
summary(arima_model_1)
```

The model has recognized a significant seasonal pattern occurring every 365 days, reinforcing the choice of using an annual pattern for seasonality treatment. But SARIMA can only capture single seasonality.

ARIMA(1,0,0)(0,1,0)[365] with drift : AICc=3604.66


```{r}
checkresiduals(arima_model_1)
```

A small p-value from Ljung-Box test suggests that there is significant autocorrelation in residuals, indicating that the model hasn't captured most of the temporal structure in the data. There are too many significant lags in ACF as well, indicating auto-correlations in the residuals. This SARIMA model is underfitting.


#### Experiment with different Sarima Models

```{r}
library(fpp)
library(TSA)
eacf(daily_ts)
```

eacf() only handles non seasonal parts of arima(p, q).


```{r}
arima_model_2 <- Arima(daily_ts, order=c(2,0,1), seasonal=c(0,1,0), include.drift=TRUE, lambda = 0.37)
summary(arima_model_2)
```

AICc=3608.68


```{r}
checkresiduals(arima_model_2)
```


```{r}
arima_model_3 <- Arima(daily_ts, order=c(1,1,0), seasonal=c(0,1,0), lambda = 0.37)
summary(arima_model_3)
```

AICc=3723.83


```{r}
arima_model_4 <- Arima(daily_ts, order=c(1,0,1), seasonal=c(0,1,0), include.drift=TRUE, lambda = 0.37)
summary(arima_model_4)
```

AICc=3606.63


```{r}
arima_model_5 <- Arima(daily_ts, order=c(1,0,2), seasonal=c(0,1,0), include.drift=TRUE, lambda = 0.37)
summary(arima_model_5)
```

AICc=3608.66


```{r}
arima_model_6 <- Arima(daily_ts, order=c(1,0,0), seasonal=c(0,1,0), lambda = 0.37)
summary(arima_model_6)
```

AICc=3633.73

Conclusion: the SARIMA model with lowest AICc is ARIMA(1,0,0)(0,1,0)[365] with drift with AICc=3604.66


#### Examine the Best SARIMA Model(Model Diagnotics): ARIMA(1,0,0)(0,1,0)[365] with drift

##### Ljung-Box test & Shapiro-Wilk normality test
```{r}
checkresiduals(arima_model_1)
shapiro.test(arima_model_1$residuals)
```

Ljung-Box test: p-value < 2.2e-16  -> residuals are autocorrelated.

Shapiro-Wilk normality test: p-value < 2.2e-16  -> residuals are not normally distributed.   


##### QQNorm plot
```{r}
qqnorm(arima_model_1$residuals,main=expression(Normal~~Q-Q~~Plot))
qqline(arima_model_1$residuals)
```

Conclusion with SARIMA Model: 

1. The best model is ARIMA(1,0,0)(0,1,0)[365] with drift with lowest AICc=3604.66.

2. But this model's residuals are autocorrelated and aren't normally distributed. There are systematic patterns in the data that the model fails to capture.

3. Therefore, this model is underfitting and the potential reason is that ARIMA/SARIMA models can only capture single seasonality.

4. I will examine multi-variable and multi-seasonality scenarios.


### Model 2: Linear Regression with Weather Variables

```{r}
final_average_df <- read.csv("final_daily_nyc_df.csv")
head(final_average_df)
tail(final_average_df)
```


```{r}
final_average_df$date <- as.Date(final_average_df$date)
```


```{r}
library(dplyr)

data_matrix <- final_average_df %>%
  select(-date) %>%
  as.matrix()

multivar_ts <- ts(data_matrix, start = c(2022, 60), frequency = 365.25)
str(multivar_ts)
```

```{r}
correlations <- cor(multivar_ts[, -11], multivar_ts[, 11])  

print(correlations)
```

#### Pick Highly Correlated Regressors

```{r}
rides <- multivar_ts[, "number_of_rides"]

# Most correlated
tmpf <- multivar_ts[, "tmpf"]
dwpf <- multivar_ts[, "dwpf"]
sknt <- multivar_ts[, "sknt"]
feel <- multivar_ts[, "feel"]

# Moderately correlated 
vsby <- multivar_ts[, "vsby"]
drct <- multivar_ts[, "drct"]
p01i <- multivar_ts[, "p01i"]

## Less correlated
relh <- multivar_ts[, "relh"]
alti <- multivar_ts[, "alti"]
mslp <- multivar_ts[, "mslp"]
```


```{r}
plot(rides, xlab = "Time")
plot(tmpf, xlab = "Time")
plot(dwpf, xlab = "Time")
plot(sknt, xlab = "Time")
plot(feel, xlab = "Time")
```


```{r}
library(forecast)
linear_model1 <- tslm(rides ~ tmpf + dwpf + sknt + feel, data = multivar_ts)
```


```{r}
print(summary(linear_model1))
print(checkresiduals(linear_model1))
```

Adjusted R-squared:  0.6351

Significant autocorrelations in residuals ; insignificant variable "feel".


```{r}
library(forecast)
linear_model2 <- tslm(rides ~ tmpf + dwpf + sknt, data = multivar_ts)
```

```{r}
print(summary(linear_model2))
print(checkresiduals(linear_model2))
```

Adjusted R-squared:  0.635


```{r}
library(forecast)
linear_model3 <- tslm(rides ~ tmpf + dwpf + sknt + feel + vsby + drct + p01i, data = multivar_ts)
```


```{r}
print(summary(linear_model3))
print(checkresiduals(linear_model3))
```

Adjusted R-squared:  0.7003


```{r}
library(forecast)
linear_model4 <- tslm(rides ~ tmpf + dwpf + sknt + feel + vsby + drct + p01i + relh + alti + mslp, data = multivar_ts)
```

```{r}
print(summary(linear_model4))
print(checkresiduals(linear_model4))
```

Adjusted R-squared:  0.7021


Conclusion:

1. Linear regressions fail to capture nonlinear, oscillation relationship in the data.

2. Residuals are autocorrelated (Breusch-Godfrey test for serial correlation), residual ACF resembles original data ACF, so this model is underfitting.

3. Use Regression With ARIMA Errors as the next step.



### Model 3: Regression With ARIMA Errors

#### Before Fitting the Model: Apply Seasonal Differencing to Make Regressors Stationary 
```{r}
library(forecast)
# Chose the 7-regressor combination from linear regression with adjusted R-squared 0.7003.
regressors1 <- c('tmpf', 'dwpf', 'sknt', 'feel', 'vsby', 'drct', 'p01i')

# Apply seasonal differencing to each regressor
seasonal_lag <- 365
diffed_regressors1 <- sapply(multivar_ts[, regressors1], function(x) diff(x, lag = seasonal_lag))

rides_aligned <- rides[-(1:seasonal_lag)]
```

```{r}
check_stationarity <- function(ts_data) {
  adf_result <- adf.test(ts_data)
  kpss_result <- kpss.test(ts_data)
  return(list(adf_p_value = adf_result$p.value, kpss_p_value = kpss_result$p.value))
}

for (i in 1:ncol(diffed_regressors1)) {
  regressor_name <- colnames(diffed_regressors1)[i]
  regressor_data <- diffed_regressors1[, i]
  
  test_results <- check_stationarity(regressor_data)
  cat("Stationarity tests for:", regressor_name, "\n")
  cat("ADF test p-value:", test_results$adf_p_value, "\n")
  cat("KPSS test p-value:", test_results$kpss_p_value, "\n\n")
}
```

```{r}
reg_arima_1 <- auto.arima(rides_aligned, xreg = diffed_regressors1, lambda = "auto", seasonal = TRUE)
```


```{r}
print(summary(reg_arima_1))
print(checkresiduals(reg_arima_1))
```

AICc=14139.66, p-value = 1.35e-09 for Ljung-Box test so residuals are autocorrelated.

In residual ACF, significant lags at 1, 7, and 21, indicating that there is still weekly seasonality in the residuals. Therefore, the multi-seasonality model is introduced.


### Model 4: Dynamic Harmonic Regression
#### Periodogram
```{r}
temp <- periodogram(daily_ts)
max_freq1 <- temp$freq[which.max(temp$spec)]
seasonality1 <- 1/max_freq1
print("First Seasonality: ")
print(seasonality1)


modified_spec <- temp$spec
modified_spec[which.max(temp$spec)] <- -Inf 
max_freq2 <- temp$freq[which.max(modified_spec)]
seasonality2 <- 1/max_freq2
print("Second Seasonality: ")
print(seasonality2)
```
```{r}
# Extract top 5 frequencies based on highest spectral power
top_freqs <- temp$freq[order(temp$spec, decreasing = TRUE)[1:5]]
top_specs <- sort(temp$spec, decreasing = TRUE)[1:5]

seasonalities <- 1 / top_freqs

results <- data.frame(Frequency = top_freqs, Spectral_Power = top_specs, Seasonality = seasonalities)
print(results)
```

Since the first seasonality/period is 384 days and the second seasonality/period is 7 days, our data has both weekly seasonality and annual seasonality.


#### Create Multi-seasonal ts object
```{r}
library(forecast)

final_average_df <- read.csv("final_daily_nyc_df.csv")
daily_msts <- msts(final_average_df$number_of_rides, seasonal.periods=c(365.25, 7), start = c(2022, 60))

summary(daily_msts)
```

#### BoxCox Transformation
```{r}
library(forecast)
lambda <- BoxCox.lambda(daily_msts)
daily_msts_boxcox <- BoxCox(daily_msts, lambda)

plot(daily_msts_boxcox, main = paste("Box-Cox Transformed Time Series Data, Lambda =", round(lambda, 2)), xlab = "Time", ylab = "Transformed Bike Rides")
```


#### Decomposition with multiple seasonal periods
```{r}
daily_msts %>% mstl() %>%
  autoplot()
```


#### Experiment with hyperparameter 'K'

```{r}
xreg <- fourier(daily_msts, K=c(3, 4))
dh_regression1 <- auto.arima(daily_msts, xreg=xreg, seasonal=FALSE, lambda = 'auto')
summary(dh_regression1)
checkresiduals(dh_regression1)

newharmonics <- fourier(daily_msts, K=c(2, 5), h=365)
fc <- forecast(dh_regression1, xreg=newharmonics)
autoplot(fc)
```

1. K=c(3, 4): Passed Ljung-Box test, AICc=6437.88, MAE=13687.02
  
2. K=c(2, 5):Passed Ljung-Box test, AICc=6433.83, MAE=13538.87

#### Selecting K and ARIMA model by minimizing AICc

```{r}
library(forecast)

bestfit<- list(aicc=Inf)
maxK_weekly <- 3  # Up to 3 because 7/2 = 3.5
maxK_annual <- 10 

for (i in 1:maxK_weekly) {
  for (j in 1:maxK_annual) {
    xreg <- fourier(daily_msts, K=c(i, j))
    fit <- auto.arima(daily_msts, xreg=xreg, seasonal=FALSE, lambda = 'auto')
    
    if (fit$aicc < bestfit$aicc) {
      bestfit <- fit
      best_K <- c(i, j)  
    }
  }
}
```

```{r}
summary(bestfit)
checkresiduals(bestfit)
```

```{r}
print(best_K)
```

```{r}
shapiro.test(bestfit$residuals)
```

Shapiro-Wilk normality test: p-value < 2.2e-16. Residuals are not normally distributed. 


```{r}
qqnorm(bestfit$residuals,main=expression(Normal~~Q-Q~~Plot))
qqline(bestfit$residuals)
```

Best K values for weekly and annual seasonality: 2, 5 with ARIMA(2,1,3) Errors.

AICc=6433.83, MAE=13538.87.

This model passed Ljung-Box test(p-value = 0.2518) but didn't pass normality test.


### Model 5: TBATS Model

```{r}
library(forecast)
tbats1 <- tbats(daily_msts)
print(tbats1)
checkresiduals(tbats1)
fc1 <- forecast(tbats1, h=365)
autoplot(fc1)
```

Model: TBATS(1, {1,2}, -, {<7,2>, <365.25,5>}).

TBATS Model gave the same values for K(2, 5) as the Dynamic Harmonic Regression but different ARIMA Errors {1,2}. This model passed Ljung-Box test. AIC=20014.01.


### Model 6: Intervention Analysis(Covid)

```{r}
inference <- read.csv("intervention_analysis_data.csv")
inference_ts <- ts(inference$number_of_rides, start = c(2018, 1), frequency = 365.25)
```

```{r}
print(head(inference_ts))
print(length(inference_ts))
plot(inference_ts, xlab = "Time", ylab = "Number of Rides", main = "Daily Bike Rides from January 2018 to March 2024")
```

Conclusion: There is no intervention effect to be modeled from Covid-19.


## 3. Model Evaluation of Forecast Accuracy via Cross-Validation

### Dynamic Harmonic Regression(expanding window and 7-day forecast horizon for cross-validation)
```{r}
library(forecast)

model_1 <- function(x, h) {
  
  if (length(x) >= 365 && length(x) + h <= length(daily_msts)) {
    # Generate Fourier terms for the current subset x directly from msts
    x_fourier <- fourier(x, K=c(2, 5))

    # Fit the ARIMA model using fixed parameters
    fit <- Arima(x, order=c(2, 1, 3), seasonal=c(0, 0, 0), xreg=x_fourier)

    # Generate Fourier terms for forecasting
    future_fourier <- fourier(x, K=c(2, 5), h=h)

    # Forecast using the fitted ARIMA model with the future Fourier terms
    fc <- forecast(fit, xreg=future_fourier)
    return(fc)
  } else {
    print("Insufficient data for fitting and forecasting.")
    return(forecast(rep(NA, h), h=h))
  }
}

harmo_error_exp <- tsCV(daily_msts, model_1, h=7, initial=365)
```


```{r}
harmo_error_exp <- na.omit(harmo_error_exp)
# print(harmo_error_exp)
```


```{r}
library(Metrics)

# Mean Error
mean_error <- mean(harmo_error_exp, na.rm = TRUE)
print(paste("Mean Error:", mean_error))

# Standard Deviation of Error
std_error <- sd(harmo_error_exp, na.rm = TRUE)
print(paste("Standard Deviation of Error:", std_error))

# Mean Absolute Error (MAE)
mae_value <- mae(harmo_error_exp, rep(0, length(harmo_error_exp)))
print(paste("Mean Absolute Error (MAE):", mae_value))

# Root Mean Squared Error (RMSE)
rmse_value <- rmse(harmo_error_exp, rep(0, length(harmo_error_exp)))
print(paste("Root Mean Squared Error (RMSE):", rmse_value))

# Mean Squared Error (MSE)
mse_value <- mse(harmo_error_exp, rep(0, length(harmo_error_exp)))
print(paste("Mean Squared Error (MSE):", mse_value))

# Median Absolute Error (MedAE)
medae_value <- median(abs(harmo_error_exp), na.rm = TRUE)
print(paste("Median Absolute Error (MedAE):", medae_value))
```


## 4. Future Forecast by Dynamic Harmonic Regression
```{r}
future_fourier <- fourier(daily_msts, K=c(2, 5), h=30)
harmo_fc <- forecast(bestfit, xreg=future_fourier, level = c(80, 95))
print(harmo_fc)
```

```{r}
plot(harmo_fc)
```

### Compare forecast values with actual bike ride demand

```{r}
test_set <- read.csv("24April_test_rides.csv")
```

```{r}
fc_values <- harmo_fc$mean
actual_values <- test_set$number_of_rides

comparison_df <- data.frame(
  Actual = actual_values,
  Forecasted = fc_values
)
print(comparison_df)
```


```{r}
fc_values <- as.numeric(fc_values)

plot(actual_values, type = 'o', pch = 19, col = 'blue', ylim = c(0, max(c(actual_values, fc_values))),
     xlab = "Days", ylab = "Number of Rides", main = "Comparison of Actual vs Forecasted Rides for April 2024",
     xaxt = 'n')

lines(fc_values, type = 'o', pch = 19, col = 'red')

legend("topleft", legend = c("Actual", "Forecasted"), col = c("blue", "red"), pch = 19, lty = 1, cex = 0.8)

axis(1, at = 1:30, labels = 1:30)
```

Observations:

The model did well on capturing the general trends in the data, especially from day 21 to day 27. The forecasts for day 2 and day 3 are relatively poor because of the unusually low actual bike demands on those 2 days.


## 5. Future Work

1. I used 2 years of data for this project. Since there is no intervention effect from Covid, I will expand the time horizon to several years in order for the models to better learn the annual patterns in data.

2. The current best model Dynamic Harmonic Regression didn't pass the normality test for its residuals. I will experiment with more advanced models like Neural Networks to solve this problem.
